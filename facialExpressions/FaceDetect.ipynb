{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./FacialExpressions_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image ID</th>\n",
       "      <th>Attentative Score/0-10</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1User1_10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2User1_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3User1_9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4User1_8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5User1_4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Image ID  Attentative Score/0-10  Unnamed: 2  Unnamed: 3  Unnamed: 4\n",
       "0  1User1_10                    10.0         NaN         NaN         NaN\n",
       "1   2User1_5                     5.0         NaN         NaN         NaN\n",
       "2   3User1_9                     9.0         NaN         NaN         NaN\n",
       "3   4User1_8                     8.0         NaN         NaN         NaN\n",
       "4   5User1_4                     4.0         NaN         NaN         NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent = '/home/rt/Documents/gayan/attentiveScore/facialExpressions/FacialExpressionDataset/FacialExpressions_800_800/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat \"/home/rt/Documents/gayan/attentiveScore/facialExpressions/FacialExpressionDataset/FacialExpressions_800_800/1User1_10.jpg\"| docker run -i think/affectiva\n",
      "55\n",
      "54\n",
      "cat \"/home/rt/Documents/gayan/attentiveScore/facialExpressions/FacialExpressionDataset/FacialExpressions_800_800/2User1_5.jpg\"| docker run -i think/affectiva\n",
      "55\n",
      "54\n",
      "  TimeStamp faceId interocularDistance glasses    age    ethnicity gender  \\\n",
      "0    0.0000      0            245.7521      no  18-24  south asian   male   \n",
      "1    0.0000      0            162.5996      no  35-44    caucasian   male   \n",
      "\n",
      "  dominantEmoji     pitch     yaw  ... disappointed    rage   smirk    wink  \\\n",
      "0       Unknown  -23.5757  6.8450  ...       0.0018  0.0040  0.0000  0.0018   \n",
      "1       Unknown   -1.6601  5.1657  ...       0.0018  0.0129  0.0000  0.0036   \n",
      "\n",
      "  stuckOutTongueWinkingEye stuckOutTongue flushed  scream      imageId  \n",
      "0                   2.2981         2.2981  0.0018  0.2483    1User1_10  \n",
      "1                   2.3035         2.3035  0.0018  0.0682     2User1_5  \n",
      "\n",
      "[2 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "df2 = []\n",
    "lines = []\n",
    "for i, row in df.iterrows():\n",
    "    if(i<2):\n",
    "        image = row['Image ID'] + '.jpg'\n",
    "        k = 'cat \"' + parent + image + '\"| docker run -i think/affectiva'\n",
    "        print(k)\n",
    "        output = execCommand('cat \"' + parent + image + '\"| docker run -i think/affectiva')\n",
    "#         output = lines\n",
    "        lines = output.split('\\n')\n",
    "        headers = lines[0].split(',')\n",
    "        if(i==0):\n",
    "            df2 = pd.DataFrame(columns=[headers])\n",
    "            df2['imageId'] = 'i'\n",
    "        lines = output.split('\\n')\n",
    "        values = lines[1].split(',')\n",
    "        values.append(row['Image ID'])\n",
    "#         values = np.array(lines[1].split(','))\n",
    "#         values = values.reshape(1,54)\n",
    "        print(len(values))\n",
    "        print(len(headers))\n",
    "        if(len(values) == len(headers)+1):\n",
    "            df2.loc[i] = values\n",
    "        else:\n",
    "            print(values)\n",
    "#         df2 = pd.concat([df2, values])\n",
    "#         break\n",
    "# print(headers)\n",
    "# print(rows)\n",
    "# df2 = pd.DataFrame(rows, columns=headers)\n",
    "print(df2.head())\n",
    "# print(df2.columns)\n",
    "# print(df2['attention'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execCommand(cmd):\n",
    "    stream = os.popen(cmd)\n",
    "    output = stream.read()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execCommand('pwd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execCommand('ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [(T,), (imageId,)]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('out2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('./out2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['attentiveness'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, r in df2.iterrows():\n",
    "    for index, row in df.iterrows():\n",
    "        if(row['Image ID'] == r['imageId']):\n",
    "            score = 1\n",
    "            if(row['Attentative Score/0-10'] != 0):\n",
    "                score = row['Attentative Score/0-10']\n",
    "            df2.loc[i, 'attentiveness'] = score\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('out2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(TimeStamp=0.0, faceId=0, interocularDistance=245.7521, glasses='no', age='18-24', ethnicity='south asian', gender='male', dominantEmoji='Unknown', pitch=-23.5757, yaw=6.845, roll=-0.1539, joy=0.0016, fear=0.0059, disgust=0.4212, sadness=0.0251, anger=0.004, surprise=0.2828, contempt=0.1928, valence=-4.4333, engagement=3.8688, smile=0.0, innerBrowRaise=3.7619, browRaise=3.8688, browFurrow=0.0004, noseWrinkle=0.0008, upperLipRaise=0.2653, lipCornerDepressor=0.0382, chinRaise=3.9751, lipPucker=3.5008, lipPress=6.1959, lipSuck=0.3115, mouthOpen=0.077, smirk=0.0038, eyeClosure=0.0, attention=95.3955, eyeWiden=0.0455, cheekRaise=0.0, lidTighten=0.0001, dimpler=41.4116, lipStretch=0.0001, jawDrop=59.8029, relaxed=0.0016, smiley=0.0016, laughing=0.0016, kissing=0.0035, disappointed=0.0018, rage=0.004, smirk.1=0.0, wink=0.0018, stuckOutTongueWinkingEye=2.2981, stuckOutTongue=2.2981, flushed=0.0018, scream=0.2483, Unnamed: 53=None, imageId='1User1_10', attentiveness=10.0)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import findspark\n",
    "# findspark.init()\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "face_df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('out2.csv')\n",
    "face_df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install pyspark\n",
    "# house_df.select('gender').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# house_df.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(house_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.feature import StringIndexer\n",
    "# indexer = StringIndexer(inputCol=\"gender\", outputCol=\"gender_new\")\n",
    "# house_df = indexer.fit(house_df).transform(house_df)\n",
    "# house_df.take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(TimeStamp=0.0, faceId=0, interocularDistance=245.7521, glasses='no', age='18-24', ethnicity='south asian', gender='male', dominantEmoji='Unknown', pitch=-23.5757, yaw=6.845, roll=-0.1539, joy=0.0016, fear=0.0059, disgust=0.4212, sadness=0.0251, anger=0.004, surprise=0.2828, contempt=0.1928, valence=-4.4333, engagement=3.8688, smile=0.0, innerBrowRaise=3.7619, browRaise=3.8688, browFurrow=0.0004, noseWrinkle=0.0008, upperLipRaise=0.2653, lipCornerDepressor=0.0382, chinRaise=3.9751, lipPucker=3.5008, lipPress=6.1959, lipSuck=0.3115, mouthOpen=0.077, smirk=0.0038, eyeClosure=0.0, attention=95.3955, eyeWiden=0.0455, cheekRaise=0.0, lidTighten=0.0001, dimpler=41.4116, lipStretch=0.0001, jawDrop=59.8029, relaxed=0.0016, smiley=0.0016, laughing=0.0016, kissing=0.0035, disappointed=0.0018, rage=0.004, smirk.1=0.0, wink=0.0018, stuckOutTongueWinkingEye=2.2981, stuckOutTongue=2.2981, flushed=0.0018, scream=0.2483, Unnamed: 53=None, imageId='1User1_10', attentiveness=10.0, features=DenseVector([0.0016, 0.0059, 0.4212, 0.0251, 0.004, 0.2828, 0.1928, -4.4333, 3.8688, 0.0, 3.7619, 3.8688, 0.0004, 0.0008, 0.2653, 0.0382, 3.9751, 3.5008, 6.1959, 0.3115, 0.077, 0.0038, 0.0, 0.0455, 0.0, 0.0001, 41.4116, 0.0001, 59.8029]))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, Normalizer, StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols = ['joy', 'fear', 'disgust', 'sadness', 'anger', 'surprise', 'contempt', 'valence', 'engagement', 'smile', 'innerBrowRaise', 'browRaise', 'browFurrow', 'noseWrinkle', 'upperLipRaise', 'lipCornerDepressor', 'chinRaise', 'lipPucker', 'lipPress', 'lipSuck', 'mouthOpen', 'smirk', 'eyeClosure', 'eyeWiden', 'cheekRaise', 'lidTighten', 'dimpler', 'lipStretch', 'jawDrop'], outputCol = 'features')\n",
    "vface_df = vectorAssembler.transform(face_df)\n",
    "vface_df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|            features|attentiveness|\n",
      "+--------------------+-------------+\n",
      "|[0.0016,0.0059,0....|         10.0|\n",
      "|[0.0013,0.006,0.4...|          5.0|\n",
      "|[0.0018,0.0052,0....|          9.0|\n",
      "+--------------------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# normalizer = Normalizer(inputCol=\"features\", outputCol=\"scaledFeatures\", p=1.0)\n",
    "# vhouse_df = normalizer.transform(vhouse_df)\n",
    "\n",
    "# scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "# Compute summary statistics and generate MinMaxScalerModel\n",
    "# scalerModel = scaler.fit(vhouse_df)\n",
    "# vhouse_df = scalerModel.transform(vhouse_df)\n",
    "\n",
    "\n",
    "# vhouse_df = vhouse_df.select(['scaledFeatures', 'attentiveness'])\n",
    "vface_df = vface_df.select(['features', 'attentiveness'])\n",
    "vface_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = vface_df.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.003885541497127465,0.0,0.0,-0.008099264668841916,0.0,-0.009035215939855653,0.0,0.0,-3.994049905867132e-05,0.0,0.0,0.0,0.0,0.0,-0.044613367254392515,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.010299957759388445]\n",
      "Intercept: 6.147538542785145\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='attentiveness', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(train_df)\n",
    "# print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "# print(\"Intercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.084876\n",
      "r2: 0.152488\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = lr_model.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|     attentiveness|\n",
      "+-------+------------------+\n",
      "|  count|               739|\n",
      "|   mean|5.7347767253044655|\n",
      "| stddev| 3.353196153217222|\n",
      "|    min|               1.0|\n",
      "|    max|              10.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------+----------+\n",
      "|       prediction|attentiveness|  features|\n",
      "+-----------------+-------------+----------+\n",
      "|6.117771779183713|          1.0|(34,[],[])|\n",
      "|6.117771779183713|          1.0|(34,[],[])|\n",
      "|6.117771779183713|          1.0|(34,[],[])|\n",
      "|6.117771779183713|          1.0|(34,[],[])|\n",
      "|6.117771779183713|          6.0|(34,[],[])|\n",
      "+-----------------+-------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R Squared (R2) on test data = 0.160105\n"
     ]
    }
   ],
   "source": [
    "lr_predictions = lr_model.transform(test_df)\n",
    "lr_predictions.select(\"prediction\",\"attentiveness\",\"features\").show(5)\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"attentiveness\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 3.05679\n"
     ]
    }
   ],
   "source": [
    "test_result = lr_model.evaluate(test_df)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+--------------------+\n",
      "|        prediction|attentiveness|            features|\n",
      "+------------------+-------------+--------------------+\n",
      "| 6.117771779183713|          1.0|          (34,[],[])|\n",
      "| 6.117771779183713|          1.0|          (34,[],[])|\n",
      "| 6.117771779183713|          1.0|          (34,[],[])|\n",
      "| 6.117771779183713|          1.0|          (34,[],[])|\n",
      "| 6.117771779183713|          6.0|          (34,[],[])|\n",
      "| 6.117771779183713|          7.0|          (34,[],[])|\n",
      "| 6.117387914916791|          7.0|(34,[0,1,2,3,4,5,...|\n",
      "| 6.070065355883991|          4.0|(34,[0,1,2,3,4,5,...|\n",
      "| 6.115278901635902|          7.0|(34,[0,1,2,3,4,5,...|\n",
      "| 6.117343458409349|          8.0|(34,[0,1,2,3,4,5,...|\n",
      "| 6.117332529221051|          7.0|(34,[0,1,2,3,4,5,...|\n",
      "| 6.117303445597998|          8.0|(34,[0,1,2,3,4,5,...|\n",
      "| 5.593763176989088|          1.0|(34,[0,1,2,3,4,5,...|\n",
      "|6.1173893267540675|          7.0|(34,[0,1,2,3,4,5,...|\n",
      "| 6.117387374909611|          4.0|(34,[0,1,2,3,4,5,...|\n",
      "| 6.116377295403572|          7.0|(34,[0,1,2,3,4,5,...|\n",
      "| 6.117391245812078|          1.0|(34,[0,1,2,3,4,5,...|\n",
      "| 6.117391049093406|          7.0|(34,[0,1,2,3,4,5,...|\n",
      "|  2.28291803495192|          1.0|(34,[0,1,2,3,4,5,...|\n",
      "|6.1173870031782025|          9.0|(34,[0,1,2,3,4,5,...|\n",
      "+------------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_model.transform(test_df)\n",
    "predictions.select(\"prediction\",\"attentiveness\",\"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Param(parent='LinearRegression_b0fafdd856ba', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 2, Param(parent='LinearRegression_b0fafdd856ba', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.8, Param(parent='LinearRegression_b0fafdd856ba', name='featuresCol', doc='features column name.'): 'features', Param(parent='LinearRegression_b0fafdd856ba', name='fitIntercept', doc='whether to fit an intercept term.'): True, Param(parent='LinearRegression_b0fafdd856ba', name='labelCol', doc='label column name.'): 'attentiveness', Param(parent='LinearRegression_b0fafdd856ba', name='predictionCol', doc='prediction column name.'): 'prediction', Param(parent='LinearRegression_b0fafdd856ba', name='solver', doc='The solver algorithm for optimization. Supported options: auto, normal, l-bfgs.'): 'auto', Param(parent='LinearRegression_b0fafdd856ba', name='standardization', doc='whether to standardize the training features before fitting the model.'): True, Param(parent='LinearRegression_b0fafdd856ba', name='epsilon', doc='The shape parameter to control the amount of robustness. Must be > 1.0. Only valid when loss is huber'): 1.35, Param(parent='LinearRegression_b0fafdd856ba', name='loss', doc='The loss function to be optimized. Supported options: squaredError, huber.'): 'squaredError', Param(parent='LinearRegression_b0fafdd856ba', name='maxIter', doc='max number of iterations (>= 0).'): 10, Param(parent='LinearRegression_b0fafdd856ba', name='regParam', doc='regularization parameter (>= 0).'): 0.3, Param(parent='LinearRegression_b0fafdd856ba', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0).'): 1e-06}\n"
     ]
    }
   ],
   "source": [
    "## Decision tree regression\n",
    "print(lr_model.extractParamMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 3.09886\n",
      "+------------------+-------------+--------------------+\n",
      "|        prediction|attentiveness|            features|\n",
      "+------------------+-------------+--------------------+\n",
      "|  3.74468085106383|          1.0|          (29,[],[])|\n",
      "|  3.74468085106383|          1.0|          (29,[],[])|\n",
      "|  3.74468085106383|          1.0|          (29,[],[])|\n",
      "|  3.74468085106383|          1.0|          (29,[],[])|\n",
      "|  3.74468085106383|          1.0|          (29,[],[])|\n",
      "|  3.74468085106383|          1.0|          (29,[],[])|\n",
      "|  3.74468085106383|          4.0|          (29,[],[])|\n",
      "|  3.74468085106383|          6.0|          (29,[],[])|\n",
      "|  3.74468085106383|          8.0|          (29,[],[])|\n",
      "|  3.74468085106383|         10.0|          (29,[],[])|\n",
      "|  3.74468085106383|         10.0|          (29,[],[])|\n",
      "| 7.502873563218391|          7.0|(29,[0,1,2,3,4,5,...|\n",
      "|3.6666666666666665|          9.0|(29,[0,1,2,3,4,5,...|\n",
      "| 2.727272727272727|          6.0|(29,[0,1,2,3,4,5,...|\n",
      "|              6.55|          1.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          6.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          1.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          9.0|(29,[0,1,2,3,4,5,...|\n",
      "| 6.888888888888889|          8.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          9.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          1.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|         10.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          8.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          7.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|         10.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          6.0|(29,[0,1,2,3,4,5,...|\n",
      "|               2.6|          5.0|(29,[0,1,2,3,4,5,...|\n",
      "|  3.74468085106383|          8.0|(29,[0,1,2,3,4,5,...|\n",
      "| 6.888888888888889|          6.0|(29,[0,1,2,3,4,5,...|\n",
      "|  3.74468085106383|          5.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|         10.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          6.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          4.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          3.0|(29,[0,1,2,3,4,5,...|\n",
      "|  3.74468085106383|          8.0|(29,[0,1,2,3,4,5,...|\n",
      "|  3.74468085106383|          6.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          8.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          1.0|(29,[0,1,2,3,4,5,...|\n",
      "| 6.888888888888889|          9.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          9.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|         10.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          8.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          9.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          8.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|         10.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          7.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          6.0|(29,[0,1,2,3,4,5,...|\n",
      "| 3.533333333333333|          1.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          1.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          6.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          6.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|         10.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          4.0|(29,[0,1,2,3,4,5,...|\n",
      "| 2.727272727272727|         10.0|(29,[0,1,2,3,4,5,...|\n",
      "|  3.74468085106383|          1.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          8.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          9.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|         10.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|         10.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          9.0|(29,[0,1,2,3,4,5,...|\n",
      "| 6.888888888888889|          8.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          6.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          9.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|         10.0|(29,[0,1,2,3,4,5,...|\n",
      "|1.2413793103448276|          1.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          7.0|(29,[0,1,2,3,4,5,...|\n",
      "|3.6666666666666665|          6.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          6.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          7.0|(29,[0,1,2,3,4,5,...|\n",
      "| 6.888888888888889|          8.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|         10.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          6.0|(29,[0,1,2,3,4,5,...|\n",
      "|               2.0|          8.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          3.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          9.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|         10.0|(29,[0,1,2,3,4,5,...|\n",
      "|1.5333333333333334|          1.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          3.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|         10.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          5.0|(29,[0,1,2,3,4,5,...|\n",
      "|1.2413793103448276|          1.0|(29,[0,1,2,3,4,5,...|\n",
      "|               6.0|         10.0|(29,[0,1,2,3,4,5,...|\n",
      "| 4.333333333333333|          1.0|(29,[0,1,2,3,4,5,...|\n",
      "| 4.117647058823529|         10.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          6.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          8.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          8.0|(29,[0,1,2,3,4,5,...|\n",
      "|               7.5|         10.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          3.0|(29,[0,1,2,3,4,5,...|\n",
      "| 6.888888888888889|         10.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          9.0|(29,[0,1,2,3,4,5,...|\n",
      "| 4.333333333333333|          8.0|(29,[0,1,2,3,4,5,...|\n",
      "|              6.55|          8.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          7.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          5.0|(29,[0,1,2,3,4,5,...|\n",
      "| 6.888888888888889|          9.0|(29,[0,1,2,3,4,5,...|\n",
      "| 7.502873563218391|          1.0|(29,[0,1,2,3,4,5,...|\n",
      "| 4.117647058823529|          7.0|(29,[0,1,2,3,5,6,...|\n",
      "| 6.888888888888889|          7.0|(29,[0,1,2,3,5,6,...|\n",
      "|1.5333333333333334|          3.0|(29,[0,1,2,3,5,6,...|\n",
      "+------------------+-------------+--------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'attentiveness')\n",
    "dt_model = dt.fit(train_df)\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "dt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"attentiveness\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "dt_predictions.select('prediction', 'attentiveness', 'features').show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosted tree regression\n",
    "dt_model.save('decisionTreeModel1.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt1 = DecisionTreeRegressor(featuresCol ='features', labelCol = 'attentiveness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_model1 = dt1.load('decisionTreeModel.pckl')\n",
    "# m = DecisionTreeRegressor.load('decisionTreeModel.pckl')\n",
    "from pyspark.ml.regression import DecisionTreeRegressionModel\n",
    "m = DecisionTreeRegressionModel.load('decisionTreeModel.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 2.4761\n",
      "+------------------+-------------+--------------------+\n",
      "|        prediction|attentiveness|            features|\n",
      "+------------------+-------------+--------------------+\n",
      "|3.8333333333333335|          1.0|          (34,[],[])|\n",
      "|3.8333333333333335|          1.0|          (34,[],[])|\n",
      "|3.8333333333333335|          1.0|          (34,[],[])|\n",
      "|3.8333333333333335|          5.0|          (34,[],[])|\n",
      "|3.8333333333333335|          6.0|          (34,[],[])|\n",
      "|3.8333333333333335|          7.0|          (34,[],[])|\n",
      "|3.8333333333333335|          8.0|          (34,[],[])|\n",
      "| 7.675090252707581|          7.0|(34,[0,1,2,3,4,5,...|\n",
      "| 6.497175141242938|          8.0|(34,[0,1,2,3,4,5,...|\n",
      "| 6.497175141242938|          4.0|(34,[0,1,2,3,4,5,...|\n",
      "| 7.675090252707581|          7.0|(34,[0,1,2,3,4,5,...|\n",
      "| 7.675090252707581|          7.0|(34,[0,1,2,3,4,5,...|\n",
      "|               8.2|          8.0|(34,[0,1,2,3,4,5,...|\n",
      "| 7.675090252707581|          7.0|(34,[0,1,2,3,4,5,...|\n",
      "| 6.497175141242938|          7.0|(34,[0,1,2,3,4,5,...|\n",
      "| 7.675090252707581|          6.0|(34,[0,1,2,3,4,5,...|\n",
      "| 7.675090252707581|          6.0|(34,[0,1,2,3,4,5,...|\n",
      "| 7.675090252707581|          7.0|(34,[0,1,2,3,4,5,...|\n",
      "| 6.497175141242938|          9.0|(34,[0,1,2,3,4,5,...|\n",
      "| 6.497175141242938|          7.0|(34,[0,1,2,3,4,5,...|\n",
      "| 7.675090252707581|          3.0|(34,[0,1,2,3,4,5,...|\n",
      "| 7.675090252707581|          3.0|(34,[0,1,2,3,4,5,...|\n",
      "| 7.675090252707581|         10.0|(34,[0,1,2,3,4,5,...|\n",
      "| 7.675090252707581|          6.0|(34,[0,1,2,3,4,5,...|\n",
      "| 7.675090252707581|         10.0|(34,[0,1,2,3,4,5,...|\n",
      "| 6.497175141242938|          7.0|(34,[0,1,2,3,4,5,...|\n",
      "| 7.675090252707581|          1.0|(34,[0,1,2,3,4,5,...|\n",
      "| 9.333333333333334|         10.0|(34,[0,1,2,3,4,5,...|\n",
      "| 6.497175141242938|          8.0|(34,[0,1,2,3,4,5,...|\n",
      "| 6.497175141242938|          6.0|(34,[0,1,2,3,5,6,...|\n",
      "| 7.675090252707581|          4.0|(34,[1,2,3,4,5,6,...|\n",
      "| 7.675090252707581|          8.0|(34,[1,2,3,4,5,6,...|\n",
      "| 7.675090252707581|         10.0|(34,[1,2,3,4,5,6,...|\n",
      "| 7.675090252707581|          6.0|(34,[1,2,3,4,5,6,...|\n",
      "| 1.355263157894737|          1.0|(34,[1,2,3,5,6,7,...|\n",
      "| 4.466666666666667|          1.0|(34,[1,2,3,5,6,7,...|\n",
      "|1.9473684210526316|          1.0|[0.0,0.0296,0.425...|\n",
      "|1.9473684210526316|          2.0|[0.0,0.1273,0.425...|\n",
      "| 6.676470588235294|          3.0|[0.0,0.197,0.4291...|\n",
      "| 7.675090252707581|         10.0|[0.0,0.5208,0.426...|\n",
      "| 7.675090252707581|         10.0|[0.0,1.3012,0.427...|\n",
      "| 7.675090252707581|          7.0|[0.0,1.8894,0.425...|\n",
      "| 7.675090252707581|         10.0|[0.0,2.6201,0.425...|\n",
      "| 7.675090252707581|         10.0|[0.0,2.6297,0.425...|\n",
      "| 5.818181818181818|          9.0|[0.0,3.0942,0.426...|\n",
      "|               3.9|          8.0|[0.0,3.4399,1.045...|\n",
      "|               3.9|          9.0|[0.0,3.4422,1.915...|\n",
      "| 6.676470588235294|          4.0|[0.0,3.4495,1.598...|\n",
      "|               3.9|          1.0|[0.0,3.5817,3.056...|\n",
      "| 6.497175141242938|          4.0|[1.0E-4,0.0058,0....|\n",
      "| 6.497175141242938|          9.0|[1.0E-4,0.0653,0....|\n",
      "| 6.497175141242938|          1.0|[1.0E-4,0.0877,0....|\n",
      "| 1.355263157894737|          9.0|[1.0E-4,0.0886,0....|\n",
      "| 6.497175141242938|          7.0|[1.0E-4,0.0934,0....|\n",
      "| 6.497175141242938|          7.0|[1.0E-4,0.0935,0....|\n",
      "| 6.666666666666667|          2.0|[1.0E-4,0.0965,0....|\n",
      "| 6.497175141242938|          9.0|[1.0E-4,0.1028,0....|\n",
      "| 6.497175141242938|          9.0|[1.0E-4,0.1098,0....|\n",
      "| 6.497175141242938|          1.0|[1.0E-4,0.111,0.4...|\n",
      "| 6.497175141242938|          6.0|[1.0E-4,0.1117,0....|\n",
      "| 6.497175141242938|         10.0|[1.0E-4,0.1153,0....|\n",
      "| 2.652173913043478|          1.0|[1.0E-4,0.1178,0....|\n",
      "| 2.652173913043478|          1.0|[2.0E-4,0.0436,0....|\n",
      "| 2.652173913043478|          6.0|[2.0E-4,0.0442,10...|\n",
      "| 6.497175141242938|          6.0|[2.0E-4,0.0494,0....|\n",
      "|1.5555555555555556|          1.0|[2.0E-4,0.2828,0....|\n",
      "| 6.497175141242938|          1.0|[3.0E-4,0.019,0.4...|\n",
      "| 6.497175141242938|          4.0|[3.0E-4,0.0208,0....|\n",
      "| 6.497175141242938|          4.0|[3.0E-4,0.0254,0....|\n",
      "| 1.355263157894737|          1.0|[3.0E-4,0.0258,0....|\n",
      "| 7.675090252707581|         10.0|[4.0E-4,0.0166,0....|\n",
      "| 1.355263157894737|          1.0|[4.0E-4,0.0693,0....|\n",
      "| 1.355263157894737|          1.0|[5.0E-4,6.0E-4,0....|\n",
      "| 7.675090252707581|          9.0|[5.0E-4,0.0147,0....|\n",
      "| 6.497175141242938|          5.0|[5.0E-4,0.0151,0....|\n",
      "| 1.355263157894737|          1.0|[5.0E-4,0.0152,0....|\n",
      "| 6.497175141242938|          9.0|[5.0E-4,0.0153,0....|\n",
      "| 6.497175141242938|          4.0|[6.0E-4,0.0122,0....|\n",
      "| 6.497175141242938|          6.0|[7.0E-4,0.0106,0....|\n",
      "| 7.675090252707581|         10.0|[7.0E-4,0.0107,0....|\n",
      "| 6.497175141242938|          2.0|[7.0E-4,0.011,0.4...|\n",
      "| 7.675090252707581|          9.0|[7.0E-4,0.012,0.4...|\n",
      "| 7.675090252707581|          9.0|[8.0E-4,0.0096,0....|\n",
      "| 4.466666666666667|          1.0|[0.001,3.0E-4,0.4...|\n",
      "| 6.497175141242938|          1.0|[0.001,0.0069,0.4...|\n",
      "| 2.652173913043478|          1.0|[0.001,0.0077,0.4...|\n",
      "| 6.497175141242938|          9.0|[0.001,0.0078,0.4...|\n",
      "| 6.497175141242938|          9.0|[0.0011,0.007,0.4...|\n",
      "| 6.497175141242938|          6.0|[0.0011,0.007,0.5...|\n",
      "| 2.652173913043478|          1.0|[0.0011,0.0072,0....|\n",
      "| 6.676470588235294|          8.0|[0.0011,0.0074,0....|\n",
      "| 6.497175141242938|          2.0|[0.0011,0.0074,0....|\n",
      "| 6.676470588235294|          4.0|[0.0011,0.0098,2....|\n",
      "| 2.652173913043478|          1.0|[0.0012,0.0066,1....|\n",
      "| 7.675090252707581|          5.0|[0.0013,0.006,0.4...|\n",
      "|               3.0|          1.0|[0.0013,0.0092,0....|\n",
      "|1.9473684210526316|          1.0|[0.0013,0.0287,1....|\n",
      "| 1.355263157894737|          2.0|[0.0014,0.0056,0....|\n",
      "| 1.355263157894737|          1.0|[0.0014,0.0057,0....|\n",
      "| 6.497175141242938|          7.0|[0.0015,0.0053,0....|\n",
      "+------------------+-------------+--------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "dt_predictions1 = m.transform(test_df)\n",
    "dt_evaluator1 = RegressionEvaluator(\n",
    "    labelCol=\"attentiveness\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = dt_evaluator1.evaluate(dt_predictions1)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "dt_predictions1.select('prediction', 'attentiveness', 'features').show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+----------+\n",
      "|        prediction|attentiveness|  features|\n",
      "+------------------+-------------+----------+\n",
      "|4.1745111723772865|          1.0|(34,[],[])|\n",
      "|4.1745111723772865|          1.0|(34,[],[])|\n",
      "|4.1745111723772865|          1.0|(34,[],[])|\n",
      "|4.1745111723772865|          1.0|(34,[],[])|\n",
      "|4.1745111723772865|          1.0|(34,[],[])|\n",
      "+------------------+-------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "gbt = GBTRegressor(featuresCol = 'features', labelCol = 'attentiveness', maxIter=10)\n",
    "gbt_model = gbt.fit(train_df)\n",
    "\n",
    "gbt_predictions = gbt_model.transform(test_df)\n",
    "gbt_predictions.select('prediction', 'attentiveness', 'features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 2.76647\n"
     ]
    }
   ],
   "source": [
    "gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"attentiveness\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.2.0.34-cp37-cp37m-macosx_10_9_x86_64.whl (49.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 49.1 MB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/site-packages (from opencv-python) (1.18.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.2.0.34\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to grab frame\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow(\"test\")\n",
    "\n",
    "img_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print(\"failed to grab frame\")\n",
    "        break\n",
    "    cv2.imshow(\"test\", frame)\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "        # SPACE pressed\n",
    "        img_name = \"opencv_frame_{}.png\".format(img_counter)\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        print(\"{} written!\".format(img_name))\n",
    "        img_counter += 1\n",
    "\n",
    "cam.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "df2;\n",
    "for i, row in df.iterrows():\n",
    "    if(i<3000):\n",
    "        image = row['Image ID'] + '.jpg'\n",
    "        output = execCommand('cat \"' + parent + image + '\"| docker run -i think/affectiva')\n",
    "        headers = lines[0].split(',')\n",
    "        if(i==0):\n",
    "            df2 = pd.DataFrame(columns=[headers])\n",
    "            df2['imageId'] = 'i'\n",
    "        lines = output.split('\\n')\n",
    "        values = lines[1].split(',')\n",
    "        values.append(row['Image ID'])\n",
    "#         values = np.array(lines[1].split(','))\n",
    "#         values = values.reshape(1,54)\n",
    "        print(len(values))\n",
    "        print(len(headers))\n",
    "        if(len(values) == len(headers)+1):\n",
    "            df2.loc[i] = values\n",
    "        else:\n",
    "            print(values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
